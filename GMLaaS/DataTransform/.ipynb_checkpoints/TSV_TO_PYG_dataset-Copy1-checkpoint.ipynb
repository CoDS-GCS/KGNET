{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d3af95-d971-4dd9-b0d2-55f77f8f66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def compress_gz(f_path):\n",
    "    f_in = open(f_path, 'rb')\n",
    "    f_out = gzip.open(f_path + \".gz\", 'wb')\n",
    "    f_out.writelines(f_in)\n",
    "    f_out.close()\n",
    "    f_in.close()\n",
    "\n",
    "\n",
    "def delete_multiple_element(list_object, indices):\n",
    "    indices = sorted(indices, reverse=True)\n",
    "    for idx in indices:\n",
    "        if idx < len(list_object):\n",
    "            list_object.pop(idx)\n",
    "   \n",
    "            \n",
    "###################### Zip Folder to OGB Format\n",
    "# zip -r mag_ComputerProgramming_papers_venue_QM3.zip mag_ComputerProgramming_papers_venue_QM3/ -i '*.gz'\n",
    "def define_rel_types(g_tsv_df):\n",
    "    g_tsv_df[\"p\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4438c2c9-f15c-4598-b0a1-e7902ed48be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing \"0\" to stype, \"1\" to ptype , and \"2\" to otype !\n",
      "New g_tsv_types df:   stype                   ptype                          otype\n",
      "0   rec           hasIdentifier           Object_hasIdentifier\n",
      "1   rec  schema#orderedCreators  Object_schema#orderedCreators\n",
      "2   rec      schema#yearOfEvent      Object_schema#yearOfEvent\n",
      "3   rec              owl#sameAs                         sameAs\n",
      "4   pid        rdf-schema#label        Object_rdf-schema#label\n",
      "original_g_csv_df loaded , records length= 454562\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='TSV to PYG')\n",
    "# #parser.add_argument('--csv_path', type=str, default=\"\")\n",
    "# parser.add_argument('--split_rel', type=str, default=\"https://dblp.org/rdf/schema#yearOfPublication\") # https://dblp.org/rdf/schema#yearOfPublication # TODO could be null in some rows\n",
    "# parser.add_argument('--target_rel', type=str, default=\"https://dblp.org/rdf/schema#publishedIn\") # https://dblp.org/rdf/schema#publishedIn\n",
    "# #split_data_type\n",
    "# #size of train # if random then in % else specific value for train and valid split\n",
    "# #size of valid\n",
    "# parser.add_argument('--target_node', type=str, default=\"paper\") # should be in node_types file (obtain using subject of target relation), 'paper'\n",
    "# parser.add_argument('--dataset_name',type=str, default=\"DBLP-Springer-Papers\") # name of generated zip file\n",
    "# parser.add_argument('--dataset_name_csv',type=str, default=\"DBLP-Springer-Papers\")  # csv/tsv , input dataset name\n",
    "# parser.add_argument('--dataset_types',type=str, default=\"\") # path to the 'types' file containing relatiolns\n",
    "# parser.add_argument('--similar_target_rels',type=list, default=[]) # 'https://dblp.org/rdf/schema#publishedInSeries' \n",
    "\n",
    "# parser.add_argument('--Literals2Nodes',type=bool, default = False) # convert literal vals into nodes (eg name of paper )or ignore \n",
    "# parser.add_argument('--output_root_path',type=str, default = \"../Datasets/\")\n",
    "# parser.add_argument('--MINIMUM_INSTANCE_THRESHOLD',type=int, default = 3)\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "start_t = datetime.datetime.now()\n",
    "dataset_name = \"DBLP-Springer-Papers\" #\"biokg_Drug_Classification\" # Name of the dataset\n",
    "dataset_name_csv = \"DBLP-Springer-Papers\" #\"biokg\"  # spo in IRI .csv no need for <>\n",
    "dataset_types = ''#\"biokg_types.csv\"  # kind of ontology\n",
    "split_rel = 'https://dblp.org/rdf/schema#yearOfPublication' #\"http://purl.org/dc/terms/year\"\n",
    "#split_by = args.split_by #{\"folder_name\": \"random\"}  # , \"split_data_type\": \"int\", \"train\":2006  ,\"valid\":2007 , \"test\":2008 }\n",
    "target_rel = \"https://dblp.org/rdf/schema#publishedIn\"  #\"https://www.biokg.org/CLASS\"  # is in the dataset and is StudiedDrug\n",
    "similar_target_rels = []#args.similar_target_rels #[\"https://www.biokg.org/SUBCLASS\", \"https://www.biokg.org/SUPERCLASS\"]\n",
    "target_node = ''  #\"drug\"  # to check -> because no labels yet\n",
    "dic_results = {}# args.dic_results #{}\n",
    "Literals2Nodes = False\n",
    "output_root_path =  \"../Datasets/\" #\"/home/ubuntu/flora_tests/biokg/data/\"\n",
    "\n",
    "if dataset_types == \"\":\n",
    "    dataset_types = output_root_path +dataset_name_csv+\"_types.csv\"\n",
    "\n",
    "g_tsv_df = pd.read_csv(output_root_path + dataset_name_csv + \".tsv\", encoding_errors='ignore', sep=\"\\t\")\n",
    "g_tsv_df[\"p\"] = g_tsv_df[\"p\"].apply(lambda x: x.split('/')[-1])\n",
    "g_tsv_types_df = pd.read_csv(dataset_types, encoding_errors='ignore',header=None)\n",
    "\n",
    "target_rel = target_rel.split('/')[-1]\n",
    "\n",
    "#Check if headers are present in _types file\n",
    "if any(col not in g_tsv_types_df.columns for col in ['stype','ptype','otype']):\n",
    "    old_columns = g_tsv_types_df.columns\n",
    "    print(f'changing \"{old_columns[0]}\" to stype, \"{old_columns[1]}\" to ptype , and \"{old_columns[2]}\" to otype !')\n",
    "    g_tsv_types_df = g_tsv_types_df.rename(columns={old_columns[0]:'stype',old_columns[1]:'ptype',old_columns[2]:'otype'})\n",
    "    print('New g_tsv_types df:',g_tsv_types_df.head())\n",
    "print(\"original_g_csv_df loaded , records length=\", len(g_tsv_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b6b0ac7-2955-4e52-a9bf-de94fbbbeda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of g_tsv_df after remove literal edges types  454562\n",
      "len of g_tsv_df after drop_duplicates   454562\n",
      "len of g_tsv_df after dropna   454562\n",
      "relations_lst= ['22-rdf-syntax-ns#type', 'rdf-schema#label', 'owl#sameAs', 'schema#bibtexType', 'schema#doi', 'schema#isbn', 'schema#numberOfCreators', 'schema#primaryElectronicEdition', 'schema#publishedBy', 'schema#title', 'schema#yearOfPublication', 'schema#publishedIn', 'schema#publishedInSeries', 'schema#otherElectronicEdition', 'schema#publishedInSeriesVolume', 'schema#editedBy', 'schema#listedOnTocPage', 'schema#type', 'schema#wikidata', 'schema#authoredBy', 'has_gnn_model', 'schema#pagination', 'schema#publishedAsPartOf', 'schema#archivedElectronicEdition', 'schema#publishedInBook', 'schema#publicationNote']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    g_tsv_df = g_tsv_df.rename(columns={\"Subject\": \"s\", \"Predicate\": \"p\", \"Object\": \"o\"})\n",
    "    g_tsv_df = g_tsv_df.rename(columns={0: \"s\", 1: \"p\", 2: \"o\"})\n",
    "    ######################## Remove Litreal Edges####################\n",
    "    Literal_edges_lst = []\n",
    "    g_tsv_df = g_tsv_df[~g_tsv_df[\"p\"].isin(Literal_edges_lst)]\n",
    "    print(\"len of g_tsv_df after remove literal edges types \", len(g_tsv_df))\n",
    "    g_tsv_df = g_tsv_df.drop_duplicates()\n",
    "    print(\"len of g_tsv_df after drop_duplicates  \", len(g_tsv_df))\n",
    "    g_tsv_df = g_tsv_df.dropna()\n",
    "    print(\"len of g_tsv_df after dropna  \", len(g_tsv_df))\n",
    "except:\n",
    "    print(\"g_tsv_df columns=\", g_tsv_df.columns())\n",
    "unique_p_lst = g_tsv_df[\"p\"].unique().tolist()\n",
    "########################delete non target nodes #####################\n",
    "relations_lst = g_tsv_df[\"p\"].unique().astype(\"str\").tolist()\n",
    "relations_lst=[rel for rel in relations_lst if rel not in similar_target_rels]\n",
    "print(\"relations_lst=\", relations_lst)\n",
    "dic_results[dataset_name] = {}\n",
    "dic_results[dataset_name][\"usecase\"] = dataset_name\n",
    "dic_results[dataset_name][\"TriplesCount\"] = len(g_tsv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b2f7e58-1c82-490a-8c1c-273a9c52a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_rel in relations_lst:\n",
    "    relations_lst.remove(target_rel)\n",
    "for srel in similar_target_rels:\n",
    "    if srel in relations_lst:\n",
    "        relations_lst.remove(srel)\n",
    "################################Start Encoding Nodes and edges ########################\n",
    "################################write relations index ########################\n",
    "relations_df = pd.DataFrame(relations_lst, columns=[\"rel name\"])\n",
    "relations_df[\"rel name\"] = relations_df[\"rel name\"].apply(lambda x: str(x).split(\"/\")[-1])\n",
    "relations_df[\"rel idx\"] = relations_df.index\n",
    "relations_df = relations_df[[\"rel idx\", \"rel name\"]]\n",
    "map_folder = output_root_path + dataset_name + \"/mapping\"\n",
    "try:\n",
    "    os.stat(map_folder)\n",
    "except:\n",
    "    os.makedirs(map_folder)\n",
    "relations_df.to_csv(map_folder + \"/relidx2relname.csv\", index=None)\n",
    "compress_gz(map_folder + \"/relidx2relname.csv\")\n",
    "############################### create labels index ########################\n",
    "label_idx_df = pd.DataFrame(\n",
    "    g_tsv_df[g_tsv_df[\"p\"] == target_rel.split('/')[-1]][\"o\"].apply(lambda x: str(x).strip()).unique().tolist(),\n",
    "    columns=[\"label name\"])\n",
    "dic_results[dataset_name][\"ClassesCount\"] = len(label_idx_df)\n",
    "try:\n",
    "    label_idx_df[\"label name\"] = label_idx_df[\"label name\"].astype(\"int64\")\n",
    "    label_idx_df = label_idx_df.sort_values(by=[\"label name\"]).reset_index(drop=True)\n",
    "except:\n",
    "    label_idx_df[\"label name\"] = label_idx_df[\"label name\"].astype(\"str\")\n",
    "    label_idx_df = label_idx_df.sort_values(by=[\"label name\"]).reset_index(drop=True)\n",
    "\n",
    "label_idx_df[\"label idx\"] = label_idx_df.index\n",
    "label_idx_df = label_idx_df[[\"label idx\", \"label name\"]]\n",
    "label_idx_df.to_csv(map_folder + \"/labelidx2labelname.csv\", index=None)\n",
    "compress_gz(map_folder + \"/labelidx2labelname.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d58e6bca-96cb-4e5b-9bce-dd6d2016c300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel_type= 22-rdf-syntax-ns#type\n",
      "rel_type= rdf-schema#label\n",
      "rel_type= owl#sameAs\n",
      "rel_type= schema#bibtexType\n",
      "rel_type= schema#doi\n",
      "rel_type= schema#isbn\n",
      "rel_type= schema#numberOfCreators\n",
      "rel_type= schema#primaryElectronicEdition\n",
      "rel_type= schema#publishedBy\n",
      "rel_type= schema#title\n",
      "rel_type= schema#yearOfPublication\n",
      "rel_type= schema#publishedInSeries\n",
      "rel_type= schema#otherElectronicEdition\n",
      "rel_type= schema#publishedInSeriesVolume\n",
      "rel_type= schema#editedBy\n",
      "rel_type= schema#listedOnTocPage\n",
      "rel_type= schema#type\n",
      "rel_type= schema#wikidata\n",
      "rel_type= schema#authoredBy\n",
      "rel_type= has_gnn_model\n",
      "rel_type= schema#pagination\n",
      "rel_type= schema#publishedAsPartOf\n",
      "rel_type= schema#archivedElectronicEdition\n",
      "rel_type= schema#publishedInBook\n",
      "rel_type= schema#publicationNote\n"
     ]
    }
   ],
   "source": [
    "relations_entites_map = {}\n",
    "relations_dic = {}\n",
    "entites_dic = {}\n",
    "# print(\"relations_lst=\",relations_lst)\n",
    "for rel in relations_lst:\n",
    "    rel_type = rel.split(\"/\")[-1]\n",
    "    # rel_type = rel\n",
    "    rel_df = g_tsv_df[g_tsv_df[\"p\"] == rel_type].reset_index(drop=True)\n",
    "    # print('& rel_df ',rel_df)\n",
    "    print(\"rel_type=\", rel_type)\n",
    "    rel_types = g_tsv_types_df[g_tsv_types_df['ptype'].isin([rel_type])]\n",
    "    # print('stype', rel_types['stype'])\n",
    "    s_type = rel_types['stype'].values[0]\n",
    "    o_type = rel_types['otype'].values[0]\n",
    "    rel_df[\"s_type\"] = s_type\n",
    "    rel_df[\"o_type\"] = o_type\n",
    "    # print('rel_df= ',rel_df)\n",
    "    #########################################################################################\n",
    "    rel_entity_types = rel_df[[\"s_type\", \"o_type\"]].drop_duplicates()\n",
    "    list_rel_types = []\n",
    "    for idx, row in rel_entity_types.iterrows():\n",
    "        list_rel_types.append((row[\"s_type\"], rel, row[\"o_type\"]))\n",
    "\n",
    "    relations_entites_map[rel] = list_rel_types\n",
    "    if len(list_rel_types) > 2:\n",
    "        print(len(list_rel_types))\n",
    "    relations_dic[rel] = rel_df\n",
    "    # e1_list=list(set(relations_dic[rel][\"s\"].apply(lambda x:str(x).split(\"/\")[:-1])))\n",
    "    for rel_pair in list_rel_types:\n",
    "        e1, rel, e2 = rel_pair\n",
    "        if e1 != \"literal\" and e1 in entites_dic:\n",
    "            entites_dic[e1] = entites_dic[e1].union(\n",
    "                set(rel_df[rel_df[\"s_type\"] == e1][\"s\"].unique()))#.apply(\n",
    "                    #lambda x: str(x).split(\"/\")[-1]).unique()))\n",
    "        elif e1 != \"literal\":\n",
    "            entites_dic[e1] = set(rel_df[rel_df[\"s_type\"] == e1][\"s\"].unique())#.apply(\n",
    "                #lambda x: str(x).split(\"/\")[-1]).unique())\n",
    "\n",
    "        if e2 != \"literal\" and e2 in entites_dic:\n",
    "            entites_dic[e2] = entites_dic[e2].union(\n",
    "                set(rel_df[rel_df[\"o_type\"] == e2][\"o\"].apply(\n",
    "                    lambda x: str(x).split(\"/\")[-1]).unique()))\n",
    "        elif e2 != \"literal\":\n",
    "            entites_dic[e2] = set(rel_df[rel_df[\"o_type\"] == e2][\"o\"].apply(\n",
    "                lambda x: str(x).split(\"/\")[-1]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5e11dec-7da8-4cf3-abb1-c7220ca17fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_node = list(g_tsv_types_df[g_tsv_types_df['ptype']==target_rel.split('/')[-1]]['stype'])[0]\n",
    "target_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb6d0ba1-5430-4b19-91c7-afeeb856758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of target_subjects_lst= 20285\n",
      "len of entites_dic[rec]= 20285\n"
     ]
    }
   ],
   "source": [
    "target_subjects_lst = g_tsv_df[g_tsv_df[\"p\"] == target_rel.split('/')[-1]][\"s\"].unique().tolist()#.apply(lambda x: str(x).split(\"/\")[-1])\n",
    "print(\"len of target_subjects_lst=\", len(target_subjects_lst))\n",
    "# target_subjects_dic= {k: entites_dic['rec'][k] for k in target_subjects_lst}\n",
    "#### Get target node\n",
    "\n",
    "entites_dic[target_node] = set.intersection(entites_dic[target_node], set(target_subjects_lst))\n",
    "print(\"len of entites_dic[\" + target_node + \"]=\", len(entites_dic[target_node]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "308e792e-4dde-4b41-b4d2-160365ccaf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(entites_dic.keys()):\n",
    "    entites_dic[key] = pd.DataFrame(list(entites_dic[key]), columns=['ent name']).astype(\n",
    "        'str').sort_values(by=\"ent name\").reset_index(drop=True)\n",
    "    entites_dic[key] = entites_dic[key].drop_duplicates()\n",
    "    entites_dic[key][\"ent idx\"] = entites_dic[key].index\n",
    "    entites_dic[key] = entites_dic[key][[\"ent idx\", \"ent name\"]]\n",
    "    entites_dic[key + \"_dic\"] = pd.Series(entites_dic[key][\"ent idx\"].values,\n",
    "                                          index=entites_dic[key][\"ent name\"]).to_dict()\n",
    "    # print(\"key=\",entites_dic[key+\"_dic\"])\n",
    "    map_folder = output_root_path + dataset_name + \"/mapping\"\n",
    "    try:\n",
    "        os.stat(map_folder)\n",
    "    except:\n",
    "        os.makedirs(map_folder)\n",
    "    entites_dic[key].to_csv(map_folder + \"/\" + key + \"_entidx2name.csv\", index=None)\n",
    "    compress_gz(map_folder + \"/\" + key + \"_entidx2name.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d930fe8-1201-4287-824e-59bfdf0fe0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_folder= ../Datasets/DBLP-Springer-Papers/raw\n"
     ]
    }
   ],
   "source": [
    "#################### write nodes statistics ######################\n",
    "lst_node_has_feat = [\n",
    "    list(\n",
    "        filter(lambda entity: str(entity).endswith(\"_dic\") == False, list(entites_dic.keys())))]\n",
    "lst_node_has_label = lst_node_has_feat.copy()\n",
    "lst_num_node_dict = lst_node_has_feat.copy()\n",
    "lst_has_feat = []\n",
    "lst_has_label = []\n",
    "lst_num_node = []\n",
    "\n",
    "for entity in lst_node_has_feat[0]:\n",
    "    if str(entity) == str(target_node):\n",
    "        lst_has_label.append(\"True\")\n",
    "        lst_has_feat.append(\"True\")\n",
    "    else:\n",
    "        lst_has_label.append(\"False\")\n",
    "        lst_has_feat.append(\"False\")\n",
    "\n",
    "    # lst_has_feat.append(\"False\")\n",
    "    lst_num_node.append(len(entites_dic[entity + \"_dic\"]))\n",
    "\n",
    "lst_node_has_feat.append(lst_has_feat)\n",
    "lst_node_has_label.append(lst_has_label)\n",
    "lst_num_node_dict.append(lst_num_node)\n",
    "\n",
    "lst_relations = []\n",
    "\n",
    "for key in list(relations_entites_map.keys()):\n",
    "    for elem in relations_entites_map[key]:\n",
    "        (e1, rel, e2) = elem\n",
    "        lst_relations.append([e1, str(rel).split(\"/\")[-1], e2])\n",
    "\n",
    "map_folder = output_root_path + dataset_name + \"/raw\"\n",
    "print(\"map_folder=\", map_folder)\n",
    "try:\n",
    "    os.stat(map_folder)\n",
    "except:\n",
    "    os.makedirs(map_folder)\n",
    "\n",
    "pd.DataFrame(lst_node_has_feat).to_csv(\n",
    "    output_root_path + dataset_name + \"/raw/nodetype-has-feat.csv\", header=None,\n",
    "    index=None)\n",
    "compress_gz(output_root_path + dataset_name + \"/raw/nodetype-has-feat.csv\")\n",
    "\n",
    "pd.DataFrame(lst_node_has_label).to_csv(\n",
    "    output_root_path + dataset_name + \"/raw/nodetype-has-label.csv\",\n",
    "    header=None, index=None)\n",
    "compress_gz(output_root_path + dataset_name + \"/raw/nodetype-has-label.csv\")\n",
    "\n",
    "pd.DataFrame(lst_num_node_dict).to_csv(\n",
    "    output_root_path + dataset_name + \"/raw/num-node-dict.csv\", header=None,\n",
    "    index=None)\n",
    "compress_gz(output_root_path + dataset_name + \"/raw/num-node-dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e24451d-a400-47af-a735-d65c1de8acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### create label relation index  ######################\n",
    "label_idx_df[\"label idx\"] = label_idx_df[\"label idx\"].astype(\"int64\")\n",
    "label_idx_df[\"label name\"] = label_idx_df[\"label name\"].apply(lambda x: str(x).split(\"/\")[-1])\n",
    "label_idx_dic = pd.Series(label_idx_df[\"label idx\"].values, index=label_idx_df[\"label name\"]).to_dict()\n",
    "############ drop multiple targets per subject keep first#######################\n",
    "labels_rel_df = g_tsv_df[g_tsv_df[\"p\"] == target_rel].reset_index(drop=True)\n",
    "labels_rel_df = labels_rel_df.sort_values(['s', 'o'], ascending=[True, True])\n",
    "labels_rel_df = labels_rel_df.drop_duplicates(subset=[\"s\"], keep='first')\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7013ea4f-09d1-4a5a-8ab1-5d38052feee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5573          https://dblp.org/rec/books/daglib/0000058\n",
       "5574          https://dblp.org/rec/books/daglib/0000497\n",
       "5575          https://dblp.org/rec/books/daglib/0000517\n",
       "5576          https://dblp.org/rec/books/daglib/0000748\n",
       "5577          https://dblp.org/rec/books/daglib/0000767\n",
       "                             ...                       \n",
       "4138       https://dblp.org/rec/series/xpert/WidhalmM02\n",
       "4139    https://dblp.org/rec/series/xpert/WieczorrekM07\n",
       "4140    https://dblp.org/rec/series/xpert/WieczorrekM08\n",
       "4141    https://dblp.org/rec/series/xpert/WieczorrekM11\n",
       "4142       https://dblp.org/rec/series/xpert/WietzkeT05\n",
       "Name: s, Length: 20285, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_type = target_rel.split(\"/\")[-1]\n",
    "rel_types = g_tsv_types_df[g_tsv_types_df['ptype'].isin([rel_type])]\n",
    "s_type = rel_types['stype'].values[0]\n",
    "o_type = rel_types['otype'].values[0]\n",
    "labels_rel_df[\"s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25a4abf3-8c76-412f-a04d-38e7b7b0a010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entites_dic= ['pid', 'rdf', 'Object_rdf-schema#label', 'rec', 'sameAs', 'net', 'doi', 'Object_schema#isbn', 'Object_schema#numberOfCreators', 'primaryElectronicEdition', 'Object_schema#publishedBy', 'Object_schema#title', 'Object_schema#yearOfEvent', 'Object_schema#publishedInSeries', 'otherElectronicEdition', 'Object_schema#publishedInSeriesVolume', 'db', 'entity', 'bool', 'Object_schema#pagination', 'archive', 'Object_schema#publishedInBook', 'Object_schema#publicationNote', 'pid_dic', 'rdf_dic', 'Object_rdf-schema#label_dic', 'rec_dic', 'sameAs_dic', 'net_dic', 'doi_dic', 'Object_schema#isbn_dic', 'Object_schema#numberOfCreators_dic', 'primaryElectronicEdition_dic', 'Object_schema#publishedBy_dic', 'Object_schema#title_dic', 'Object_schema#yearOfEvent_dic', 'Object_schema#publishedInSeries_dic', 'otherElectronicEdition_dic', 'Object_schema#publishedInSeriesVolume_dic', 'db_dic', 'entity_dic', 'bool_dic', 'Object_schema#pagination_dic', 'archive_dic', 'Object_schema#publishedInBook_dic', 'Object_schema#publicationNote_dic']\n"
     ]
    }
   ],
   "source": [
    "rel_type = target_rel.split(\"/\")[-1]\n",
    "rel_types = g_tsv_types_df[g_tsv_types_df['ptype'].isin([rel_type])]\n",
    "s_type = rel_types['stype'].values[0]\n",
    "o_type = rel_types['otype'].values[0]\n",
    "s_label_type = target_node\n",
    "o_label_type = o_type\n",
    "label_type = target_node\n",
    "labels_rel_df[\"s_idx\"] = labels_rel_df[\"s\"].apply(\n",
    "    lambda x: str(x).split(\"/\")[-1])\n",
    "labels_rel_df[\"s_idx\"] = labels_rel_df[\"s_idx\"].astype(\"str\")\n",
    "print(\"entites_dic=\", list(entites_dic.keys()))\n",
    "labels_rel_df[\"s_idx\"] = labels_rel_df[\"s_idx\"].apply(\n",
    "    lambda x: entites_dic[s_label_type + \"_dic\"][x] if x in entites_dic[\n",
    "        s_label_type + \"_dic\"].keys() else -1)\n",
    "labels_rel_df_notfound = labels_rel_df[labels_rel_df[\"s_idx\"] == -1]\n",
    "labels_rel_df = labels_rel_df[labels_rel_df[\"s_idx\"] != -1]\n",
    "labels_rel_df = labels_rel_df.sort_values(by=[\"s_idx\"]).reset_index(drop=True)\n",
    "\n",
    "labels_rel_df[\"o_idx\"] = labels_rel_df[\"o\"].apply(lambda x: str(x).split(\"/\")[-1])\n",
    "labels_rel_df[\"o_idx\"] = labels_rel_df[\"o_idx\"].apply(\n",
    "    lambda x: label_idx_dic[str(x)] if str(x) in label_idx_dic.keys() else -1)\n",
    "out_labels_df = labels_rel_df[[\"o_idx\"]]\n",
    "map_folder = output_root_path + dataset_name + \"/raw/node-label/\" + s_label_type\n",
    "try:\n",
    "    os.stat(map_folder)\n",
    "except:\n",
    "    os.makedirs(map_folder)\n",
    "out_labels_df.to_csv(map_folder + \"/node-label.csv\", header=None, index=None)\n",
    "compress_gz(map_folder + \"/node-label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece31de3-9a28-41e4-a67a-834ee6b76cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target nodes count= 20285\n",
      "target_nodes_to_keep_lst count= 20285\n",
      "labels_dict count= 440\n",
      "labels_to_keep count= 199\n"
     ]
    }
   ],
   "source": [
    "###########################################split parts (train/test/validate)#########################\n",
    "# split_df = g_tsv_df[g_tsv_df[\"p\"] == split_rel]\n",
    "split_df = g_tsv_df[g_tsv_df[\"p\"] == target_rel]\n",
    "########## remove drug  with multi labels ################\n",
    "target_label_dict = split_df[\"s\"].value_counts().to_dict()\n",
    "target_nodes_to_keep_lst = list(k for k, v in target_label_dict.items() if v == 1)\n",
    "print(\"target nodes count=\", len(target_label_dict.keys()))\n",
    "print(\"target_nodes_to_keep_lst count=\", len(target_nodes_to_keep_lst))\n",
    "split_df = split_df[split_df[\"s\"].isin(target_nodes_to_keep_lst)]\n",
    "########## remove labels with less than 9 samples################\n",
    "labels_dict = split_df[\"o\"].value_counts().to_dict()\n",
    "#MINIMUM_INSTANCE_THRESHOLD = args.MINIMUM_INSTANCE_THRESHOLD\n",
    "labels_to_keep_lst = list(k for k, v in labels_dict.items() if v >= 3) # 9\n",
    "print(\"labels_dict count=\", len(labels_dict.keys()))\n",
    "print(\"labels_to_keep count=\", len(labels_to_keep_lst))\n",
    "split_df = split_df[split_df[\"o\"].isin(labels_to_keep_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac9faf-0cba-431d-be4c-d4e3d47ff4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PYG]",
   "language": "python",
   "name": "conda-env-PYG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
